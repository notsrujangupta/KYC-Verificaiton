{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face Matching App.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notsrujangupta/KYC-Verificaiton/blob/main/Face_Matching_App.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6tgGx3wBJMi"
      },
      "source": [
        "#Installations and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8WMAvLk1BLA"
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6CdPA9qBFHx"
      },
      "source": [
        "pip install Keras-Applications"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eFBdJfJBOqZ"
      },
      "source": [
        "## Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zps9Yy_afBa3"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from matplotlib import pyplot\n",
        "from numpy import asarray\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "import tensorflow\n",
        "tensorflow.__version__\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface import utils\n",
        "from keras import optimizers\n",
        "from keras.models import Model, Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import random\n",
        "random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmrgJE5IgSss"
      },
      "source": [
        "class IdentityMetadata():\n",
        "    def __init__(self, base, name, file):\n",
        "        self.base = base\n",
        "        self.name = name\n",
        "        self.file = file\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.image_path()\n",
        "\n",
        "    def image_path(self):\n",
        "        return os.path.join(self.base, self.name, self.file) \n",
        "    \n",
        "def load_metadata(path):\n",
        "    metadata = []\n",
        "    for i in os.listdir(path):\n",
        "        for f in os.listdir(os.path.join(path, i)):\n",
        "            ext = os.path.splitext(f)[1]\n",
        "            if ext == '.jpg' or ext == '.jpeg':\n",
        "                metadata.append(IdentityMetadata(path, i, f))\n",
        "    return np.array(metadata)\n",
        "\n",
        "def img_embd(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    embd_temp = image.img_to_array(img)\n",
        "    embd_temp = (embd_temp / 255.).astype(np.float32)\n",
        "    embd_temp = np.expand_dims(embd_temp, axis=0)\n",
        "    embd_temp = utils.preprocess_input(embd_temp, version=2)\n",
        "    return embd_temp\n",
        "\n",
        "def emb_vec(arr):\n",
        "    embedding_vector = model.predict(arr)[0]\n",
        "    return embedding_vector\n",
        "\n",
        "def distance_from_embd(vec1,vec2):\n",
        "    return cosine(vec1,vec2)\n",
        "\n",
        "def distance(path1, path2):\n",
        "    embd1 = img_embd(path1)\n",
        "    embd2 = img_embd(path2)\n",
        "    vec1 = emb_vec(embd1)\n",
        "    vec2 = emb_vec(embd2)\n",
        "    return cosine(vec1,vec2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yidxboe-BbSH"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JebOA_dMDhv7"
      },
      "source": [
        "# Model/Data Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flH9HWiTDpIG"
      },
      "source": [
        "## Defining ROOT_PATH and checking distance metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW5Z0c6RgqRM"
      },
      "source": [
        "ROOT_PATH = #root path of all image folders/files after data generation is complete (smile data with photos of photos of smile photos)\n",
        "file1_path = #file path\n",
        "file2_path = #file path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE8TS61-gyBo"
      },
      "source": [
        "model = model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czwOVpdXg70E"
      },
      "source": [
        "distance(ROOT_PATH+file1_path, ROOT_PATH+file2_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmEbW7wYkE1x"
      },
      "source": [
        "## Step 0: Initial Data Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsWo3Pn6jMLw"
      },
      "source": [
        "\"\"\"Put labelled data in 3 folders: \"Correct\", \"Correct_fake\" and \"Incorrect\" with phone images of people in the \"Correct\" folder and the images in \"Correct_fake\" such that images of images of people are in the corresponding order as their \"Correct\" values. All the other images go into \"Incorrect\". \n",
        "Corrupt files checkers: \n",
        "1. BadPeggy (Download: https://www.coderslagoon.com, Github Source Code: https://github.com/llaith-oss/BadPeggy) to check for corrupted image files in the folders easily. \n",
        "2. ImagMagick (Download: https://imagemagick.org/script/download.php)\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha7LPeSOkLrl"
      },
      "source": [
        "## Step 1: Data Pre-Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBu-0WN0ksvG"
      },
      "source": [
        "### Creating imagelist, Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFo9Ese7kSzK"
      },
      "source": [
        "meta_correct = load_metadata(ROOT_PATH+\"Correct\")\n",
        "meta_fake = load_metadata(ROOT_PATH+\"Correct_fake\")\n",
        "meta_incorrect = load_metadata(ROOT_PATH+\"Incorrect\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPBlW9AokJUc"
      },
      "source": [
        "### Image Agumentation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcTR0MOVjYLk"
      },
      "source": [
        "# could hypothetically try to extract face with MTCNN, not sure if it's needed though. Perhaps it's relevant how the edges of the face meet the background?\n",
        "\n",
        "array_correct = []\n",
        "for i in range(0,len(meta_correct)):\n",
        "    arr_temp = img_embd(meta_correct[i].image_path())\n",
        "    array_correct.append(arr_temp)\n",
        "\n",
        "np.savez(ROOT_PATH+\"array_correct.npz\", array_correct)\n",
        "\n",
        "array_fake = []\n",
        "for i in range(0,len(meta_fake)):\n",
        "    arr_temp = img_embd(meta_fake[i].image_path())\n",
        "    array_fake.append(arr_temp)\n",
        "\n",
        "np.savez(ROOT_PATH+\"array_fake.npz\", array_fake)\n",
        "\n",
        "array_incorrect = []\n",
        "for i in range(0,len(meta_incorrect)):\n",
        "    arr_temp = img_embd(meta_incorrect[i].image_path())\n",
        "    array_incorrect.append(arr_temp)\n",
        "\n",
        "np.savez(ROOT_PATH+\"array_incorrect.npz\", array_incorrect)\n",
        "\n",
        "\n",
        "#Change n,m and run these lines to get some sort of an idea to visualise the images and see what things may be needed to be done.\n",
        "n = 3\n",
        "m = 51\n",
        "pyplot.imshow(meta_correct[n])\n",
        "pyplot.imshow(meta_fake[n])\n",
        "pyplot.imshow(meta_incorrect[m])\n",
        "\n",
        "\n",
        "#GANs could be pretty useful for the next part.\n",
        "imgen = ImageDataGenerator(rotation_range=30, zoom_range=[0.2,0.5], width_shift_range=0.3, height_shift_range=0.3, shear_range=0.2, horizontal_flip=True, fill_mode=\"nearest\", brightness_range = [0.1,1.0])\n",
        "\n",
        "num = 0\n",
        "for img in array_correct:\n",
        "    image = imgen.flow(img, batch_size=1, save_to_dir=args[ROOT_PATH+\"Correct_Aug\"],save_prefix=num+\"_image\", save_format=\"jpg\")\n",
        "    num += 1\n",
        "\n",
        "meta_aug = load_metadata(ROOT_PATH+\"Correct_Aug\")\n",
        "array_aug = []\n",
        "for i in range(0,len(meta_aug)):\n",
        "    arr_temp = img_embd(meta_aug[i].image_path())\n",
        "    array_aug.append(arr_temp)\n",
        "\n",
        "np.savez(ROOT_PATH+\"array_aug.npz\", array_aug)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow6IWNG6keJr"
      },
      "source": [
        "## Step 2: pairplots, pairgrids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIbmJxVCkgiI"
      },
      "source": [
        "this section is entirely hypothetical, and we can try various things based on other info we have about the data (ID etc) and do the normal pd.read_csv and make pairgrids and see what new info we may or may not gather about the specific situations. This is usually not going to be super worth it, but it just might. eg: in pairplots, we can change hue to be area of face and see what happens there. This is ultimately not as important as the iamges themselves in this situation since the primary work is with said images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wacN1mQ6koPX"
      },
      "source": [
        "## Step 3: Model + Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmjgb9dujfFL"
      },
      "source": [
        "\n",
        "model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
        "\n",
        "embeddings_correct = []\n",
        "for img array_correct:\n",
        "  try:\n",
        "    embedding_vector = emb_vec(img)\n",
        "  except:\n",
        "    embedding_vector = [0] * 2622\n",
        "  embeddings_correct.append(embedding_vector)\n",
        "\n",
        "np.savez(ROOT_PATH+\"embeddings_correct.npz\", embeddings_correct)\n",
        "\n",
        "embeddings_fake = []\n",
        "for img array_fake:\n",
        "  try:\n",
        "    embedding_vector = emb_vec(img)\n",
        "  except:\n",
        "    embedding_vector = [0] * 2622\n",
        "  embeddings_fake.append(embedding_vector)\n",
        "\n",
        "np.savez(ROOT_PATH+\"embeddings_fake.npz\", embeddings_fake)\n",
        "\n",
        "embeddings_incorrect = []\n",
        "for img array_incorrect:\n",
        "  try:\n",
        "    embedding_vector = emb_vec(img)\n",
        "  except:\n",
        "    embedding_vector = [0] * 2622\n",
        "  embeddings_incorrect.append(embedding_vector)\n",
        "\n",
        "np.savez(ROOT_PATH+\"embeddings_incorrect.npz\", embeddings_incorrect)\n",
        "\n",
        "\n",
        "embeddings_aug = []\n",
        "for img array_aug:\n",
        "  try:\n",
        "    embedding_vector = emb_vec(img)\n",
        "  except:\n",
        "    embedding_vector = [0] * 2622\n",
        "  embeddings_aug.append(embedding_vector)\n",
        "\n",
        "np.savez(ROOT_PATH+\"embeddings_aug.npz\", embeddings_aug)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saB4fWrYk5HX"
      },
      "source": [
        "Not sure how to figure out an appropriate threshold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1exrB_Ejoz4"
      },
      "source": [
        "\"\"\"distance function gives us all the info we need about the distances between the images themselves. I'll probably need to work with real data before I can talk about something more specific\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xteCUTboNPDR"
      },
      "source": [
        "arr = np.concatenate((embeddings_correct, embeddings_fake, embeddings_incorrect, embeddings_aug), axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufxj4H-hU-9R"
      },
      "source": [
        "dist_arr = np.zeros([len(arr),len(arr)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEFvnQylMTr_"
      },
      "source": [
        "for i in range(len(arr)):\n",
        "    for j in range(i): #to avoid too much time taken, we are not repeating values\n",
        "        dist_arr[i][j] = distance_from_embd(arr[i],arr[j])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npOqftPnOKPD"
      },
      "source": [
        "dist_arr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGY5115tOhD6"
      },
      "source": [
        "\"\"\"This give us all the distances from each image to the other. We can use this information to create a good threshold. I'm trying to avoid Deep Learning here because it feels like unnecessary computation, but if we had no option, we could always use it for finding a good threshold.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}